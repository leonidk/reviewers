{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy, scipy.stats\n",
    "#import autograd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('spring_2021.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Num == '16824'][['Year','Num','Total # Students','Hrs Per Week','Instructor',\"Overall teaching rate\",\"Overall course rate\"]]#.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = {'Sem':'Semester','Course Level':'Level','Num':'Course ID','Instructor':'Name','Total # Students':'Tot'}\n",
    "df.columns = [fix.get(x,x) for x in df.columns]\n",
    "df.Name = df.Name.map(lambda x: x.upper() if type(x) == str else _)\n",
    "df_orig = df \n",
    "\n",
    "# FIX THE BROKEN\n",
    "div = (df['Overall course rate']-1e-9)//5 + 1\n",
    "df.iloc[:,-9:] = df.iloc[:,-9:].divide(div,'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=df[(df.Year ==2020) & (df.Semester == 'Fall') & (df.Dept == 'ROB')& (df.Level == 'Graduate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Overall course rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "dfft = df[df['College'] == ' School of Computer Science']\n",
    "dfft = dfft[dfft['# Responses'] >= 25]\n",
    "dfft = dfft[dfft['Year'] > 2015]\n",
    "#dfft = dfft[dfft['Dept'] == \"MLG\"]\n",
    "\n",
    "# ax =sns.lmplot(x=\"Hrs Per Week\", y=\"Overall course rate\", data=dfft, hue='Level',line_kws={'color':'k'},scatter_kws={'alpha':0.2,'s':dfft['# Responses']})\n",
    "\n",
    "ax =sns.lmplot(x=\"Hrs Per Week\", y=\"Overall course rate\", data=dfft, hue='Level',scatter_kws={'alpha':0.4})\n",
    "#plt.setp(ax.collections[1], alpha=0.5)\n",
    "plt.ylim(3.0,5.0)\n",
    "plt.title('SCS Courses',size=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfft = df[df['College'] == ' School of Computer Science']\n",
    "dfft = dfft[dfft.Level == 'Graduate']\n",
    "dfft = dfft[dfft['# Responses'] >= 5]\n",
    "#dfft = dfft[dfft['Year'] > 2015]\n",
    "dfft = dfft[dfft['Dept'] == \"CS\"]\n",
    "\n",
    "# ax =sns.lmplot(x=\"Hrs Per Week\", y=\"Overall course rate\", data=dfft, hue='Level',line_kws={'color':'k'},scatter_kws={'alpha':0.2,'s':dfft['# Responses']})\n",
    "\n",
    "ax =sns.lmplot(x=\"Tot\", y=\"Overall course rate\", data=dfft,scatter_kws={'alpha':0.4},line_kws={'color':'k'})\n",
    "#plt.setp(ax.collections[1], alpha=0.5)\n",
    "plt.ylim(3.0,5.0)\n",
    "plt.title('Graduate CS classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[(df.Dept == 'ROB')& (df.Level == 'Graduate') & (df.Name == 'GALEOTTI, JOHN')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.groupby('Course ID').mean()['Overall course rate'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_code_to_dept = defaultdict(lambda : defaultdict(int))\n",
    "for row in df.itertuples():\n",
    "    course_code_to_dept[row[5][:2]][row[4]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_code_to_dept = {k: sorted([(c,x) for x,c in v.items()])[-1][1] for k,v in course_code_to_dept.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    DF_EXPAND = pd.read_excel('copied_data.xlsx')\n",
    "\n",
    "    ID_lookup = {}\n",
    "    for row in df.itertuples():\n",
    "        ID_lookup[row[7]] = row[8]\n",
    "    for row in DF_EXPAND.itertuples():\n",
    "        if row[7] not in ID_lookup:\n",
    "            ID_lookup[row[7]] = row[7].lower().replace(' ','').replace(',','')\n",
    "            #print(ID_lookup[row[7]])\n",
    "    DF_EXPAND['Instructor ID'] = DF_EXPAND['Name'].apply(lambda x: ID_lookup[x])\n",
    "    df = pd.concat([df_orig,DF_EXPAND],sort=False,ignore_index=True)\n",
    "df['Course ID'] = df['Course ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Course ID']== str(16697),'Course ID'] = str(16698)\n",
    "df.loc[df['Course ID']== str(16730),'Course ID'] = str(16698)\n",
    "df = df[df.Name.map(lambda x: type(x) == str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIME'] = (df['Year']-df['Year'].min())*2 + np.array(df['Semester'] == 'Fall').astype(np.int)\n",
    "df['TIME'] = (df['TIME'] +1)\n",
    "df['TIME'] = ((df['TIME'])/df['TIME'].max())\n",
    "df.TIME = df.TIME**2\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-white')\n",
    "plt.plot(df.groupby('Year').mean()['TIME'],lw=4)\n",
    "plt.ylabel('weight',size=20)\n",
    "plt.xlabel('year',size=20)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.gca().tick_params(axis='both', which='minor', labelsize=16)\n",
    "plt.grid(True)\n",
    "plt.title('time weights',size=24)\n",
    "plt.tight_layout()\n",
    "plt.savefig('time-bias.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = list(df['Course ID'].unique())\n",
    "reviewers = list(df['Name'].unique()) #Login ID\n",
    "rm = df['Overall course rate'].mean()\n",
    "rs = df['Overall course rate'].std()\n",
    "rm,rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BANNED_NAMES = ['INDEPENDENT STUDY','INDEPENDENT STUDY','SEM.','SEMN','SEMNR','SP TPCS','SPEC TOPICS','READING','SPECIAL TOPICS','PRACTICUM','INTERNSHIP','SEMINAR','PROJECT','CAPSTONE']\n",
    "#BANNED_NAMES = ['INDEPENDENT STUDY','INDEPENDENT STUDY','SEM.','SEMN','SEMNR','READING','PRACTICUM','INTERNSHIP','SEMINAR','PROJECT','CAPSTONE']\n",
    "\n",
    "valid_names = df['Course Name'].apply(lambda x: sum([_ in x for _ in BANNED_NAMES]) == 0)\n",
    "#df= df.loc[valid_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectsD = {k:i for i,k in enumerate(subjects)}\n",
    "reviewersD = {k:i for i,k in enumerate(reviewers)}\n",
    "#NAME_IDX = list(df.columns).index('Login ID')\n",
    "NAME_IDX = list(df.columns).index('Name')\n",
    "FULLN_idx = list(df.columns).index('Name')\n",
    "CN_IDX  = list(df.columns).index('Course Name')\n",
    "COURSE_IDX = list(df.columns).index('Course ID')\n",
    "SIZE_IDX = list(df.columns).index('# Responses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_sub = len(subjects)\n",
    "n_rev = len(reviewers)\n",
    "dataset = np.array(df)\n",
    "total_reviews = np.zeros(n_sub)\n",
    "num_reviews = np.zeros(n_sub)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(dataset.shape[0]):\n",
    "    #print(dataset[i,4],dataset[i,6],dataset[i,23])\n",
    "    dataset[i,0] = subjectsD[dataset[i,COURSE_IDX]]\n",
    "    dataset[i,1] = reviewersD[dataset[i,NAME_IDX]]\n",
    "    #dataset[i,2] = (dataset[i,2]-rm)/rs\n",
    "    \n",
    "    # normalization step\n",
    "    total_reviews[dataset[i,0]] += dataset[i,SIZE_IDX]\n",
    "    num_reviews[dataset[i,0]] += 1\n",
    "\n",
    "average_reviews = total_reviews/num_reviews\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_biases = np.random.randn(n_rev)\n",
    "subject_scores = np.random.random(n_sub)\n",
    "\n",
    "x0 = np.hstack([reviewer_biases,subject_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dataset[:,0]).shape,n_sub,n_rev,np.unique(dataset[:,1]).shape,x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_w = np.sqrt(df.Tot.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csize = df.iloc[:,SIZE_IDX].unique()\n",
    "csize = np.array(sorted(csize))\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.plot(csize,np.sqrt(csize)/max_w,lw=4)\n",
    "plt.ylabel('weight',size=20)\n",
    "plt.xlabel('number of respondents',size=20)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.gca().tick_params(axis='both', which='minor', labelsize=16)\n",
    "plt.grid(True)\n",
    "plt.title('size weights',size=24)\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('size-bias.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dept_means = df.loc[valid_names].groupby(['Dept','Level']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df.columns).index('Level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns).index('# Responses'),list(df.columns).index('Dept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPT_IDX = list(df.columns).index('Dept')\n",
    "LEVEL_IDX = list(df.columns).index('Level')\n",
    "SCORE_IDX = list(df.columns).index('Overall course rate')\n",
    "TIME_IDX = list(df.columns).index('TIME')\n",
    "\n",
    "DEPT_IDX,LEVEL_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_bias = defaultdict(float)\n",
    "\n",
    "dept_bias_cnt = defaultdict(float)\n",
    "for row in df.loc[valid_names].itertuples():\n",
    "    #print(row)\n",
    "    key = row[DEPT_IDX+1],row[LEVEL_IDX+1]\n",
    "    val,num = row[SCORE_IDX+1],row[SIZE_IDX+1]\n",
    "    #print(row[4],row[9],row[24],row[12])\n",
    "    if np.isfinite(val):\n",
    "        dept_bias[key] += val*num\n",
    "        dept_bias_cnt[key] += num\n",
    "\n",
    "for k in dept_bias:\n",
    "    dept_bias[k]/=dept_bias_cnt[k]\n",
    "#dept_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_bias = np.zeros(n_sub)\n",
    "for row in df.itertuples():\n",
    "    course_bias[subjectsD[row[COURSE_IDX+1]]] = dept_bias[(row[DEPT_IDX+1],row[LEVEL_IDX+1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_names = sorted([_ for _ in dept_bias])\n",
    "n_depts = len(dept_names)\n",
    "n_dept_idx = {k:i for i,k in enumerate(dept_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0,1,3,7,8,11,23,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = {}\n",
    "y = np.zeros(dataset.shape[0])\n",
    "bias = np.zeros(dataset.shape[0])\n",
    "for i,d in enumerate(dataset):\n",
    "    if np.isfinite(d[SCORE_IDX]):\n",
    "        valid_bias = sum([_ in d[CN_IDX] for _ in BANNED_NAMES]) ==0\n",
    "        valid_bias = max(0.01,float(valid_bias))\n",
    "        \n",
    "        is_grad = 0.5*int(d[LEVEL_IDX] == 'Graduate') + 0.5\n",
    "        W =  valid_bias*is_grad*d[TIME_IDX]*np.sqrt(d[SIZE_IDX])/max_w#np.sqrt(d[11]))\n",
    "        Xd[(i,d[0])] = W\n",
    "        Xd[(i,n_sub+d[1])] = W\n",
    "        \n",
    "        bias_idx = n_dept_idx[(d[DEPT_IDX],d[LEVEL_IDX])]#['Overall course rate']\n",
    "        Xd[(i,n_sub+n_rev+bias_idx)] = W\n",
    "        y[i] = (d[SCORE_IDX])*W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjects\n",
    "n_rev,n_sub,n_depts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = scipy.sparse.dok_matrix((dataset.shape[0],n_rev+n_sub+n_depts))\n",
    "X._update(Xd)\n",
    "X = scipy.sparse.csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,y.max(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = X.T\n",
    "Xt = XT @ X\n",
    "Xy = XT @ y.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regV = np.ones(n_rev+n_sub+n_depts)*2e-2\n",
    "regV[n_sub:] = 2e-2\n",
    "regV[-n_depts:] = 0\n",
    "x = scipy.linalg.solve(Xt + scipy.diag(regV), Xy, assume_a='pos')\n",
    "diff = X.dot(x)[:,0] - y\n",
    "# (0.006937218147652276, 2.87071151664889)\n",
    "abs(diff).mean(),np.linalg.norm(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(diff**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erm = scipy.linalg.inv(Xt + np.diag(regV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = np.sqrt(np.diag(mse*erm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = scipy.stats.t.ppf(0.95,df=len(diff))\n",
    "CI = cv*sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(diff,100)\n",
    "plt.xlim(-.3,.3)\n",
    "plt.grid(True)\n",
    "plt.ylabel('number of examples',size=20)\n",
    "plt.xlabel('prediction error',size=20)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.gca().tick_params(axis='both', which='minor', labelsize=16)\n",
    "plt.grid(True)\n",
    "plt.title('Distribution of errors',size=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction-error.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    xv = np.random.uniform(-6,-1,size=6)\n",
    "    xv = np.sort(xv)\n",
    "    Vs = []\n",
    "    for lr in xv:\n",
    "        regV = np.ones(n_rev+n_sub)*1e-3\n",
    "        regV[n_sub:] = (10**(lr))\n",
    "        x = scipy.linalg.solve(Xt + scipy.diag(regV), Xy, assume_a='pos')\n",
    "        diff = X.dot(x)[:,0] - y\n",
    "        Vs.append((lr,abs(diff).mean(),np.linalg.norm(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    Vs = np.array(Vs)\n",
    "    plt.plot(Vs[:,0],Vs[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(Vs[:,0],Vs[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dept_bias= x[-n_depts:,0]\n",
    "reviewer_biases = x[n_sub:-n_depts,0]\n",
    "course_offsets = x[:n_sub,0]\n",
    "\n",
    "CI_reg_dept_bias= CI[-n_depts:]\n",
    "CI_reviewer_biases = CI[n_sub:-n_depts]\n",
    "CI_course_offsets = CI[:n_sub]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    course_bias[subjectsD[row[COURSE_IDX+1]]] = reg_dept_bias[n_dept_idx[(row[DEPT_IDX+1],row[LEVEL_IDX+1])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_scores = course_offsets + course_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in dept_names:\n",
    "    print(n,reg_dept_bias[n_dept_idx[n]],dept_bias[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(reviewer_biases,50)\n",
    "plt.ylabel('number of examples',size=20)\n",
    "plt.xlabel('instructor bias',size=20)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.gca().tick_params(axis='both', which='minor', labelsize=16)\n",
    "plt.grid(True)\n",
    "plt.xlim(-1,1)\n",
    "plt.title('instructor offsets',size=24)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pred-inst.pdf')\n",
    "\n",
    "plt.figure()\n",
    "_ = plt.hist(x[:n_sub,0],50)\n",
    "plt.ylabel('number of examples',size=20)\n",
    "plt.xlabel('course bias from department average',size=20)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.gca().tick_params(axis='both', which='minor', labelsize=16)\n",
    "plt.grid(True)\n",
    "plt.xlim(-1,1)\n",
    "plt.title('course offsets',size=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pred-offset.pdf')\n",
    "\n",
    "plt.figure()\n",
    "_ = plt.hist(subject_scores,50)\n",
    "plt.ylabel('number of examples',size=20)\n",
    "plt.xlabel('predicted \"core\" course scores',size=20)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.gca().tick_params(axis='both', which='minor', labelsize=16)\n",
    "plt.grid(True)\n",
    "plt.title('subject scores',size=24)\n",
    "plt.xlim(2.5,5.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pred-scores.pdf')\n",
    "\n",
    "plt.figure()\n",
    "_ = plt.hist(reg_dept_bias,50)\n",
    "plt.ylabel('number of examples',size=20)\n",
    "plt.xlabel('dept average',size=20)\n",
    "plt.gca().tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.gca().tick_params(axis='both', which='minor', labelsize=16)\n",
    "plt.grid(True)\n",
    "plt.title('dept average scores',size=24)\n",
    "plt.xlim(3,5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dept_bias.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_set = df[(df.Level == 'Graduate') & ((df.Dept == 'ROB') | (df.Dept == 'zzz'))]\n",
    "#valid_Iids = set(base_set['Login ID'].unique())\n",
    "valid_Iids = set(base_set['Name'].unique())\n",
    "valid_Cids = set(base_set['Course ID'].unique())\n",
    "df.Dept.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for n in df[df.Dept == 'ROB']['Course Name']:\n",
    "#    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class_lookup = defaultdict(list)\n",
    "name_lookup = defaultdict(list)\n",
    "\n",
    "for row in df.itertuples():\n",
    "    #print(row[7],'\\t',row[5],'\\t',row[4],'\\t',row[8])\n",
    "    #name_lookup[row[7]].append(row[6])\n",
    "    class_lookup[row[COURSE_IDX+1]].append(row[CN_IDX+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_bias[('MEG','Graduate')],dept_bias[('MLG','Graduate')],dept_bias[('ROB','Graduate')],dept_bias[('STA','Graduate')],dept_bias[('CS','Graduate')],dept_bias[('HCI','Graduate')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewers[i]\n",
    "#name_lookup\n",
    "len(reviewer_biases),len(reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('{:40s}\\t\\t{}\\t{}'.format('name','bias','95%'))\n",
    "\n",
    "cnt = 0\n",
    "for i in np.argsort(reviewer_biases):\n",
    "    if reviewers[i] not in valid_Iids:\n",
    "        continue\n",
    "    print('{:40s}\\t\\t{:.2f}\\t{:.2f}'.format(reviewers[i],reviewer_biases[i],CI_reviewer_biases[i]))\n",
    "    cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:40s}\\t\\t{}\\t{}'.format('class','score','95%'))\n",
    "scores = []\n",
    "for i in np.argsort(subject_scores):\n",
    "    if subjects[i] not in valid_Cids:\n",
    "        continue\n",
    "    if subject_scores[i] == 0:\n",
    "        continue\n",
    "    scores.append(subject_scores[i])\n",
    "    print('{:40s}\\t\\t{:.2f}\\t{:.2f}'.format(class_lookup[subjects[i]][0],subject_scores[i],CI_course_offsets[i]))\n",
    "scores = np.array(scores)\n",
    "scores.mean(),scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "if False:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    #plt.scatter(average_reviews,subject_scores+(average_reviews.mean()-subject_scores.mean()))\n",
    "    plt.scatter(average_reviews,subject_scores)\n",
    "    plt.xlabel('average review')\n",
    "    plt.ylabel('true review')\n",
    "    maxv = max(abs(average_reviews).max(),abs(subject_scores).max())\n",
    "    #plt.xlim(-maxv,maxv)\n",
    "    #plt.ylim(-maxv,maxv)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lookup = defaultdict(list)\n",
    "for name in df.Name.unique():\n",
    "    if type(name) == str:\n",
    "        last = name.split(', ')[0]\n",
    "        short_lookup[last].append(name)\n",
    "        \n",
    "login_lookup = defaultdict(list)\n",
    "for row in df.itertuples():\n",
    "    login_lookup[row[FULLN_idx+1]].append(row[NAME_IDX+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_lookup = {k: list(set(v)) for k,v in login_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = pd.read_html('spring22.html')\n",
    "html_data_orig = html_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(html_data)):\n",
    "    html_data[i].loc[:,'Course'] = html_data_orig[i].Course.map(lambda x: np.nan if type(x) == str and x == 'nan' else x)\n",
    "    html_data[i] = html_data[i].ffill()\n",
    "    #html_data[i].dropna(subset=['Course'],inplace=True)\n",
    "    html_data[i].loc[:,'Course'] = html_data[i].Course.map(lambda x: str(int(x)))\n",
    "    html_data[i].loc[:,'Instructor'] = html_data[i].Instructor.map(lambda x: x.replace('  ',';'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(html_data)):\n",
    "    html_data[i].loc[:,'Course'] = html_data[i].Course.map(lambda x: '0' + x if len(x) ==4 else x)\n",
    "    html_data[i] =  html_data[i].drop_duplicates(['Course','Instructor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "for d in html_data:\n",
    "    results = []\n",
    "    DEPT_NUM = d.loc[0].Course[:2]\n",
    "    print('\\n\\nNOW DOING THE {} DEPARTMENT\\n'.format(DEPT_NUM))\n",
    "    for row in d.itertuples():\n",
    "        #print(row)\n",
    "        cv = subject_scores[subjectsD[str(row[1])]] if str(row[1]) in subjectsD else 0\n",
    "        row_dept = str(row[1])\n",
    "        if cv == 0:\n",
    "            if row_dept[:2] in course_code_to_dept and (course_code_to_dept[row_dept[:2]],'Undergraduate') in n_dept_idx:\n",
    "                cv = reg_dept_bias[n_dept_idx[(course_code_to_dept[row_dept[:2]],'Undergraduate')]]\n",
    "            else:\n",
    "                #print(row)\n",
    "                cv = reg_dept_bias.mean()\n",
    "        #print(row[-1])\n",
    "        nv = []\n",
    "        NAMES = row[-1]\n",
    "        if 'Pathak' in NAMES and 'Gupta' in NAMES:\n",
    "            NAMES = 'Pathak, Deepak'\n",
    "        for fname in NAMES.split(';'):\n",
    "            fname = fname.replace(\"'\",'')\n",
    "            sname = fname.upper().split(',')\n",
    "            first_name = sname[-1]\n",
    "            last_name = sname[0]\n",
    "            #print(first_name,last_name)\n",
    "\n",
    "            list_of_names = short_lookup[last_name]  \n",
    "            #print(fname,list_of_names)\n",
    "            if fname.upper() in list_of_names:\n",
    "                #print(fname)\n",
    "                list_of_names = [fname.upper()]\n",
    "            #print(fname,list_of_names,len(list_of_names))\n",
    "\n",
    "            if len(list_of_names) == 0:\n",
    "                print('didnt find ' + fname)\n",
    "            if len(list_of_names) > 1:\n",
    "                print('ambig ',fname, list_of_names)\n",
    "                list_of_names = []\n",
    "            nv.append(list_of_names)\n",
    "        #print(row[-1],nv)\n",
    "        nvL = [reviewer_biases[reviewersD[login_lookup[_[0]][0]]]  if len(_) > 0 else 0 for _ in nv ]\n",
    "        nv = np.mean(nvL) if len(nvL) > 0 else 0\n",
    "        TR = cv + nv if len(nvL) >0 else 0\n",
    "        if TR <=0.1:\n",
    "            print(row)\n",
    "            continue\n",
    "        new_name = ', '.join([ _.split(',')[0] if ',' in _ else _ for _ in NAMES.split(';')])\n",
    "        #print(new_name)\n",
    "        #print(new_name)\n",
    "        d = {'num':row[1],'name':row[2],'Instructor':new_name,'Instructor Rating':nv,'Course Rating':cv,'Total Rating':TR}\n",
    "        d['course %'] = scipy.stats.percentileofscore(subject_scores,cv)\n",
    "        d['instru %'] = scipy.stats.percentileofscore(reviewer_biases,nv)\n",
    "        #d['total %'] = scipy.stats.percentileofscore(total_scores_vec['Overall course rate'].fillna(0),TR)\n",
    "\n",
    "        results.append(d)\n",
    "    #RES = pd.DataFrame(results)[['num','name','Instructor','Course Rating','Instructor Rating','Total Rating','course %','instru %','total %']]\n",
    "    RES = pd.DataFrame(results)[['num','name','Instructor','Course Rating','Instructor Rating','Total Rating']]\n",
    "\n",
    "    #RES = pd.DataFrame(results)[['num','name','Instructor','course %','instru %','total %']]\n",
    "    RES = RES.sort_values('Total Rating',0,False)\n",
    "    RES['num'] = RES['num'].astype(str)\n",
    "    RES['num'] = RES['num'].apply(lambda x: x[:2] + '-' + x[2:])\n",
    "    #RES.columns = ['num', 'name', 'Instructor', 'Course Estimate', 'Instructor Estimate', 'Total Estimate']\n",
    "    all_results[DEPT_NUM] =RES\n",
    "    #RES.round(0).style.background_gradient(cmap='RdYlGn',low=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['16'].round(3).style.background_gradient(cmap='RdYlGn')#.to_excel('pred_tmp_NEW.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_to_print = set(pd.read_excel('big_res2.xlsx').num)\n",
    "36,16,15,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP = pd.concat([all_results[str(_)] for _ in ['16','10','15','36']]).sort_values('Total Rating',0,False).set_index('num').round(2)\n",
    "print()\n",
    "def test(x):\n",
    "    res = False\n",
    "    for t in ['Capstone','Reading','Practicum','Independent Study','Seminar','Elective','Advanced Topics','Interdisciplinary Applied Research']:\n",
    "        res |= t.lower() in x.lower()\n",
    "    return res\n",
    "\n",
    "TMP = TMP[TMP.name.map(lambda x: not test(x))]\n",
    "print(TMP.shape)\n",
    "#TMP = TMP[TMP.index.isin(valid_to_print)]\n",
    "TMP.reset_index().style.background_gradient(cmap='RdYlGn').to_excel('big_res_NEW.xlsx')\n",
    "TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['16'].round(2).style.background_gradient(cmap='RdYlGn').to_excel('pred_tmp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['16'].set_index('num')['Total Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['Course ID'] = dft['Course ID'].map(lambda x: str(x)[:2] + '-' + str(x)[2:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugr = all_results['16'].set_index('num')\n",
    "debugr['actual'] = dft.groupby('Course ID').mean()['Overall course rate']\n",
    "debugr['error'] = debugr['actual'] - debugr['Total Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debugr['updated pred'] = all_results['16'].set_index('num')['Total Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugr#.dropna().round(2).style.background_gradient(cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(debugr['error'],5)\n",
    "plt.title('sigma: {:.2f}'.format(debugr['error'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugr.dropna().round(2).style.background_gradient(cmap='RdYlGn')#.to_excel('update.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
