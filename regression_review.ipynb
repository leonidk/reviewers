{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import autograd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nice_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = list(df.subject.unique())\n",
    "reviewers = list(df.reviewer.unique())\n",
    "rm = df.score.mean()\n",
    "rs = df.score.std()\n",
    "\n",
    "n_sub = len(subjects)\n",
    "n_rev = len(reviewers)\n",
    "dataset = np.array(df)\n",
    "total_reviews = np.zeros(n_sub)\n",
    "num_reviews = np.zeros(n_sub)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(dataset.shape[0]):\n",
    "    dataset[i,0] = subjects.index(dataset[i,0])\n",
    "    dataset[i,1] = reviewers.index(dataset[i,1])\n",
    "    #dataset[i,2] = (dataset[i,2]-rm)/rs\n",
    "    \n",
    "    # normalization step\n",
    "    total_reviews[dataset[i,0]] += dataset[i,2]\n",
    "    num_reviews[dataset[i,0]] += 1\n",
    "\n",
    "average_reviews = total_reviews/num_reviews\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_means = np.zeros(n_rev)\n",
    "reviewer_std = np.zeros(n_rev)\n",
    "for idx,reviewer in enumerate(reviewers):\n",
    "    reviewer_means[idx] = df[df.reviewer == reviewer].score.mean()\n",
    "    reviewer_std[idx] = df[df.reviewer == reviewer].score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_biases = np.random.randn(n_rev)\n",
    "subject_scores = np.random.random(n_sub)\n",
    "reg_l2= 1/2\n",
    "lr = 1e-9\n",
    "num_iter = 5000\n",
    "x0 = np.hstack([reviewer_biases,subject_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x):\n",
    "    res = 0\n",
    "    rb = x[:n_rev]\n",
    "    ss = x[n_rev:]\n",
    "    #d = dataset[np.random.randint(dataset.shape[0])]\n",
    "    #res = res + (d[2]-rb[d[1]]-ss[d[0]])**2 + reg_l2* (rb**2).sum()\n",
    "    for d in dataset:\n",
    "        res = res + (d[2]-rb[d[1]]-ss[d[0]])**2\n",
    "    res = res+ reg_l2* (rb**2).sum()\n",
    "    return res\n",
    "loss(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    J = autograd.jacobian(loss)\n",
    "    x = x0\n",
    "    for i in range(50):\n",
    "        g = J(x)\n",
    "        l = loss(x)\n",
    "        x = x - lr * g\n",
    "        #x = x - lr/pow(i+1,0.5) * g\n",
    "        if (i % 2 == 0):\n",
    "            #print(l,sum([loss(x) for _ in range(100)]))\n",
    "            print(l)\n",
    "        if(i % 10 == 0):\n",
    "            lr = lr/4\n",
    "else:\n",
    "    import scipy.optimize as opt\n",
    "    res = opt.minimize(loss,x0)\n",
    "    x = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_biases = x[:n_rev]\n",
    "subject_scores = x[n_rev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}\\t\\t{}'.format('name','bias'))\n",
    "\n",
    "for i in np.argsort(reviewer_biases):\n",
    "    print('{}\\t\\t{:.2f}'.format(reviewers[i],reviewer_biases[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}\\t\\t{}\\t{}'.format('name','mean','std'))\n",
    "for i in np.argsort(reviewer_means):\n",
    "    print('{}\\t\\t{:.2f}\\t{:.2f}'.format(reviewers[i],reviewer_means[i],reviewer_std[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "#plt.scatter(average_reviews,subject_scores+(average_reviews.mean()-subject_scores.mean()))\n",
    "plt.scatter(average_reviews,subject_scores)\n",
    "plt.xlabel('average review')\n",
    "plt.ylabel('true review')\n",
    "maxv = max(abs(average_reviews).max(),abs(subject_scores).max())\n",
    "#plt.xlim(-maxv,maxv)\n",
    "#plt.ylim(-maxv,maxv)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
